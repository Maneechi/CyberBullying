# -*- coding: utf-8 -*-
"""Cyber Bullying detection

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ugaYjmp_fpjkG6cHvKgtbpctRMyhc3IQ
"""

pip install xgboost

pip install plotly

pip install pythainlp

pip install sklearn

pip install --upgrade --pre pythainlp

"""#Import Libraries"""

import os
import glob
import time
import json
import pytz
import random

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from google.colab import files 
#from google.colab import auth
from datetime import datetime

from numpy import mean, std
from sklearn.feature_selection import chi2, mutual_info_classif, f_classif, f_regression
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, Normalizer

from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold

from sklearn.metrics import (accuracy_score, roc_auc_score, roc_curve, precision_recall_curve, 
                             f1_score, auc, plot_confusion_matrix, plot_precision_recall_curve, RocCurveDisplay)

from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, SparsePCA, FastICA, TruncatedSVD
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection

from sklearn.linear_model import LogisticRegression 
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

from sklearn.pipeline import Pipeline

"""##Load Dataset"""

#uploaded = files.upload()

#def load_data(file: str):
  #df = pd.read_csv(file, header=None, sep='\t', names=['string','type'])
  #df.names="text"
  #df.replace(to_replace = ['neg'],value=' ')
  #df.replace(to_replace = np.NaN, value ='neg')
  #return df

#df = load_data("Cyber_data.txt")
#dfp['type'] = 'pos'
#df = df.drop(df.index[249])
#df

df= pd.read_csv("https://raw.githubusercontent.com/Maneechi/Cyberbullying/cyberbullying-detection/Cyber_data.txt", header=None, sep='\t', names=['string','type'])
df

from pythainlp.tokenize import word_tokenize
text = "ขอโทษที่รบกวนคะ"
word_tokenize(text, engine="newmm")

from pythainlp.corpus.common import thai_stopwords
thai_stopwords = list(thai_stopwords())
#thai_stopwords

from pythainlp import word_tokenize
def text_process(text):
    final = "".join(u for u in text if u not in ("?", ".", ";", ":", "!", '"', "ๆ", "ฯ"))
    final = word_tokenize(final)
    final = " ".join(word for word in final)
    #final = " ".join(word for word in final.split() 
    #if word.lower not in thai_stopwords)
    return final

df['string'] = df['string'].apply(text_process)
df

"""##Split data"""

from sklearn.model_selection import train_test_split
X = df[['string']]
y = df['type']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)

from sklearn.feature_extraction.text import CountVectorizer
cvec = CountVectorizer(analyzer=lambda x:x.split(' '))
cvec.fit_transform(X_train['string'])
cvec.vocabulary_

train_bow = cvec.transform(X_train['string'])
pd.DataFrame(train_bow.toarray(), columns=cvec.get_feature_names(), index=X_train['string'])

random_seed=10

"""#Test"""

lr = LogisticRegression()
lr.fit(train_bow, y_train)

from sklearn.metrics import confusion_matrix,classification_report, plot_confusion_matrix
test_bow = cvec.transform(X_test['string'])
test_predictions = lr.predict(test_bow)
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(lr, test_bow, y_test)  
plt.show()

sv = SVC(kernel="linear")
sv.fit(train_bow, y_train)

from sklearn.metrics import confusion_matrix,classification_report
test_bow = cvec.transform(X_test['string'])
test_predictions = sv.predict(test_bow)
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(sv, test_bow, y_test)  
plt.show()

kn = KNeighborsClassifier (n_neighbors=6)
kn.fit(train_bow, y_train)

from sklearn.metrics import confusion_matrix,classification_report
test_bow = cvec.transform(X_test['string'])
test_predictions = kn.predict(test_bow)
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(kn, test_bow, y_test)  
plt.show()

dt = DecisionTreeClassifier(
            criterion = "entropy", random_state = 10,
            max_depth = 3, min_samples_leaf = 5)
dt.fit(train_bow, y_train)

from sklearn.metrics import confusion_matrix,classification_report
test_bow = cvec.transform(X_test['string'])
test_predictions = dt.predict(test_bow)
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(dt, test_bow, y_test)  
plt.show()

dtg = DecisionTreeClassifier(criterion = "gini",
            random_state = 100,max_depth=3, min_samples_leaf=5)
dtg.fit(train_bow, y_train)

from sklearn.metrics import confusion_matrix,classification_report
test_bow = cvec.transform(X_test['string'])
test_predictions = dtg.predict(test_bow)
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(dtg, test_bow, y_test)  
plt.show()

gb = GaussianNB()
gb.fit(train_bow.toarray(), y_train)

test_bow = cvec.transform(X_test['string'])
test_predictions = gb.predict(test_bow.toarray())
print(classification_report(test_predictions, y_test))
plot_confusion_matrix(gb, test_bow.toarray(), y_test)  
plt.show()

my_text = 'ที่บ้านมีเสื้อตัวเดียวหรอ '
my_tokens = text_process(my_text)
my_bow = cvec.transform(pd.Series([my_tokens]))
my_predictions = sv.predict(my_bow)
my_predictions

my_text = 'ตรงปกส่งไวครับ'
my_tokens = text_process(my_text)
my_bow = cvec.transform(pd.Series([my_tokens]))
my_predictions = lr.predict(my_bow)
my_predictions

my_text = 'fuckผู้หญิงเลว'
my_tokens = text_process(my_text)
my_bow = cvec.transform(pd.Series([my_tokens]))
my_predictions = lr.predict(my_bow)
my_predictions

import pickle
with open('Cyberbullyingdetection_sv.pkl', 'wb') as file:
  pickle.dump(sv, file)